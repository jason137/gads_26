<!-- author: Jason Dolatshahi -->

# lec 10 exercises
## ensemble classifiers

Complete these exercises in groups of 2 or 3. Try to make your responses as
simple as possible.

### no computers

1) Define the following terms:
- random forest
- adaptive sampling
- base classifier
- bagging
- resampling/boostrapping
- decision surface
- decision stump
- boosting

2) Why do decision trees make good base classifiers? Why might logistic
regression models not make good base classifiers?

3) How do bagging, boosting, and random forests address the statistical &
mathematical conceptual problems in classification?

4) Why does low bias correspond to high variance?

### yes computers

5) Compare the performance of a single decision tree, a random forest, and a
boosted classifer (like `GradientBoostingClassifier`) on the multi-class
problem using the data in `abalone.csv`. What can you say about the relative
performance of each? Does hyperparameter tuning change your results?
